import os
import json
from typing import List, Dict, Any
from sqlalchemy.orm import Session
from app.crud.policy_tag import policy_tag_crud
from app.services.vector import index, embeddings
from app.models.policy_tag import PolicyTag

class PolicyTagVectorService:
    """æ”¿ç­–ã‚¿ã‚°ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨Pineconeä¿å­˜ã‚’ç®¡ç†ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹"""

    def __init__(self):
        self.namespace = "policy_tags"
        self.vector_dimension = 1536  # OpenAI text-embedding-ada-002ã®æ¬¡å…ƒæ•°

    def vectorize_policy_tags(self, db: Session) -> Dict[str, Any]:
        """
        MySQLã®policy_tagsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€
        ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Pineconeã«ä¿å­˜ã™ã‚‹
        
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœã®è©³ç´°
        """
        try:
            # MySQLã‹ã‚‰å…¨ã¦ã®policy_tagsã‚’å–å¾—
            policy_tags = policy_tag_crud.get_all_policy_tags(db)
            
            if not policy_tags:
                return {
                    "success": False,
                    "message": "policy_tagsãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“",
                    "processed_count": 0
                }

            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            vectors_to_upsert = []
            texts_to_embed = []
            
            for tag in policy_tags:
                # idã¨nameã‚’çµ„ã¿åˆã‚ã›ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
                text = f"ID: {tag.id}, Name: {tag.name}"
                texts_to_embed.append(text)
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                metadata = {
                    "tag_id": tag.id,
                    "tag_name": tag.name,
                    "type": "policy_tag",
                    "created_at": tag.created_at.isoformat() if tag.created_at else None
                }
                
                vectors_to_upsert.append({
                    "id": f"policy_tag_{tag.id}",
                    "metadata": metadata
                })

            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            print(f"ğŸ” {len(texts_to_embed)}å€‹ã®æ”¿ç­–ã‚¿ã‚°ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
            embeddings_list = embeddings.embed_documents(texts_to_embed)
            
            # ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã€MySQLã¨Pineconeã®ä¸¡æ–¹ã«ä¿å­˜
            for i, embedding in enumerate(embeddings_list):
                vectors_to_upsert[i]["values"] = embedding
                
                # MySQLã®embeddingã‚«ãƒ©ãƒ ã«ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                tag = policy_tags[i]
                embedding_data = {
                    "vector": embedding,
                    "text": texts_to_embed[i],
                    "metadata": vectors_to_upsert[i]["metadata"]
                }
                tag.embedding = json.dumps(embedding_data, ensure_ascii=False)
            
            # MySQLã®å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
            db.commit()

            # Pineconeã«ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿å­˜
            print(f"ğŸ’¾ Pineconeã«{len(vectors_to_upsert)}å€‹ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿å­˜ä¸­...")
            index.upsert(
                vectors=vectors_to_upsert,
                namespace=self.namespace
            )

            return {
                "success": True,
                "message": f"{len(vectors_to_upsert)}å€‹ã®æ”¿ç­–ã‚¿ã‚°ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Pineconeã«ä¿å­˜ã—ã¾ã—ãŸ",
                "processed_count": len(vectors_to_upsert),
                "namespace": self.namespace
            }

        except Exception as e:
            print(f"âŒ æ”¿ç­–ã‚¿ã‚°ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "success": False,
                "message": f"ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                "processed_count": 0
            }

    def vectorize_single_policy_tag(self, db: Session, tag_id: int) -> Dict[str, Any]:
        """
        æŒ‡å®šã•ã‚ŒãŸIDã®æ”¿ç­–ã‚¿ã‚°ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Pineconeã«ä¿å­˜ã™ã‚‹
        
        Args:
            db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
            tag_id: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹ã‚¿ã‚°ã®ID
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœã®è©³ç´°
        """
        try:
            # æŒ‡å®šã•ã‚ŒãŸIDã®æ”¿ç­–ã‚¿ã‚°ã‚’å–å¾—
            policy_tag = policy_tag_crud.get_policy_tag_by_id(db, tag_id)
            
            if not policy_tag:
                return {
                    "success": False,
                    "message": f"ID {tag_id} ã®æ”¿ç­–ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                    "processed_count": 0
                }

            # idã¨nameã‚’çµ„ã¿åˆã‚ã›ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
            text = f"ID: {policy_tag.id}, Name: {policy_tag.name}"
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            print(f"ğŸ” æ”¿ç­–ã‚¿ã‚° (ID: {tag_id}) ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
            embedding = embeddings.embed_query(text)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            metadata = {
                "tag_id": policy_tag.id,
                "tag_name": policy_tag.name,
                "type": "policy_tag",
                "created_at": policy_tag.created_at.isoformat() if policy_tag.created_at else None
            }
            
            # MySQLã®embeddingã‚«ãƒ©ãƒ ã«ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            embedding_data = {
                "vector": embedding,
                "text": text,
                "metadata": metadata
            }
            policy_tag.embedding = json.dumps(embedding_data, ensure_ascii=False)
            db.commit()
            
            # Pineconeã«ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿å­˜
            vector_data = {
                "id": f"policy_tag_{policy_tag.id}",
                "values": embedding,
                "metadata": metadata
            }
            
            print(f"ğŸ’¾ Pineconeã«æ”¿ç­–ã‚¿ã‚° (ID: {tag_id}) ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿å­˜ä¸­...")
            index.upsert(
                vectors=[vector_data],
                namespace=self.namespace
            )

            return {
                "success": True,
                "message": f"æ”¿ç­–ã‚¿ã‚° (ID: {tag_id}) ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Pineconeã«ä¿å­˜ã—ã¾ã—ãŸ",
                "processed_count": 1,
                "namespace": self.namespace
            }

        except Exception as e:
            print(f"âŒ æ”¿ç­–ã‚¿ã‚° (ID: {tag_id}) ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "success": False,
                "message": f"ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                "processed_count": 0
            }

    def search_similar_policy_tags(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        ã‚¯ã‚¨ãƒªã«é¡ä¼¼ã—ãŸæ”¿ç­–ã‚¿ã‚°ã‚’æ¤œç´¢ã™ã‚‹
        
        Args:
            query (str): æ¤œç´¢ã‚¯ã‚¨ãƒª
            top_k (int): è¿”ã™çµæœã®æ•°
            
        Returns:
            List[Dict[str, Any]]: é¡ä¼¼ã—ãŸæ”¿ç­–ã‚¿ã‚°ã®ãƒªã‚¹ãƒˆ
        """
        try:
            # ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            query_embedding = embeddings.embed_query(query)
            
            # Pineconeã§é¡ä¼¼æ¤œç´¢
            results = index.query(
                vector=query_embedding,
                namespace=self.namespace,
                top_k=top_k,
                include_metadata=True
            )
            
            # çµæœã‚’æ•´å½¢
            similar_tags = []
            for match in results.matches:
                similar_tags.append({
                    "tag_id": match.metadata.get("tag_id"),
                    "tag_name": match.metadata.get("tag_name"),
                    "score": match.score,
                    "created_at": match.metadata.get("created_at")
                })
            
            return similar_tags

        except Exception as e:
            print(f"âŒ æ”¿ç­–ã‚¿ã‚°æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []

    def delete_policy_tag_vectors(self, tag_ids: List[int]) -> Dict[str, Any]:
        """
        æŒ‡å®šã•ã‚ŒãŸIDã®æ”¿ç­–ã‚¿ã‚°ãƒ™ã‚¯ãƒˆãƒ«ã‚’Pineconeã‹ã‚‰å‰Šé™¤ã™ã‚‹
        
        Args:
            tag_ids (List[int]): å‰Šé™¤ã™ã‚‹ã‚¿ã‚°ã®IDãƒªã‚¹ãƒˆ
            
        Returns:
            Dict[str, Any]: å‰Šé™¤çµæœ
        """
        try:
            # å‰Šé™¤ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã®IDã‚’æº–å‚™
            vector_ids = [f"policy_tag_{tag_id}" for tag_id in tag_ids]
            
            # Pineconeã‹ã‚‰å‰Šé™¤
            index.delete(
                ids=vector_ids,
                namespace=self.namespace
            )
            
            return {
                "success": True,
                "message": f"{len(vector_ids)}å€‹ã®æ”¿ç­–ã‚¿ã‚°ãƒ™ã‚¯ãƒˆãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ",
                "deleted_count": len(vector_ids)
            }

        except Exception as e:
            print(f"âŒ æ”¿ç­–ã‚¿ã‚°ãƒ™ã‚¯ãƒˆãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "success": False,
                "message": f"ãƒ™ã‚¯ãƒˆãƒ«å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                "deleted_count": 0
            }

    def get_vector_statistics(self) -> Dict[str, Any]:
        """
        Pineconeã®ãƒ™ã‚¯ãƒˆãƒ«çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹
        
        Returns:
            Dict[str, Any]: çµ±è¨ˆæƒ…å ±
        """
        try:
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
            stats = index.describe_index_stats()
            
            # policy_tagsãƒãƒ¼ãƒ ã‚¹ãƒšãƒ¼ã‚¹ã®æƒ…å ±ã‚’å–å¾—
            namespace_stats = stats.namespaces.get(self.namespace, {})
            
            return {
                "success": True,
                "total_vector_count": stats.total_vector_count,
                "policy_tags_vector_count": namespace_stats.get("vector_count", 0),
                "dimension": stats.dimension,
                "index_fullness": stats.index_fullness,
                "namespaces": list(stats.namespaces.keys())
            }

        except Exception as e:
            print(f"âŒ çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "success": False,
                "message": f"çµ±è¨ˆæƒ…å ±å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }

# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
policy_tag_vector_service = PolicyTagVectorService()
