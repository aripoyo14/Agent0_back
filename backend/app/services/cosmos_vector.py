import os
import json
from typing import Dict, Any, List, Union, Tuple
from datetime import datetime, timezone, timedelta
from pymongo import MongoClient
from pymongo.collection import Collection
from pymongo.database import Database
from langchain_openai import OpenAIEmbeddings
from sqlalchemy.orm import Session
from app.core.config import get_settings
from app.crud.policy_tag import policy_tag_crud
from app.models.policy_tag import PolicyTag
from app.crud.experts_policy_tags import experts_policy_tags_crud
from app.models.experts_policy_tags import ExpertsPolicyTag

# æ—¥æœ¬æ¨™æº–æ™‚ï¼ˆJSTï¼‰
JST = timezone(timedelta(hours=9))

class CosmosVectorService:
    """Azure Cosmos DB for MongoDB vCoreã‚’ä½¿ç”¨ã—ãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹"""

    def __init__(self):
        # è¨­å®šã‚’å–å¾—
        settings = get_settings()
        self.cosmos_connection_string = settings.cosmos_connection_string
        self.database_name = settings.cosmos_database_name
        self.collection_name = settings.cosmos_collection_name
        
        if not self.cosmos_connection_string:
            raise RuntimeError("COSMOS_CONNECTION_STRING is missing in environment variables")
        
        # MongoDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        self.client = MongoClient(self.cosmos_connection_string)
        self.database: Database = self.client[self.database_name]
        self.collection: Collection = self.database[self.collection_name]
        
        # Embeddingãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆæœ€æ–°ã®å°å‹ãƒ¢ãƒ‡ãƒ«ã«æ›´æ–°ï¼‰
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        
        # ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒæ•°ï¼ˆtext-embedding-3-small ã¯ 1536 æ¬¡å…ƒï¼‰
        self.vector_dimension = 1536

    def vectorize_summary(
        self, 
        summary_title: str, 
        summary_content: str, 
        expert_id: str, 
        tag_ids: Union[int, List[int], str],
        summary_id: str = None
    ) -> Dict[str, Any]:
        """
        è¦ç´„å†…å®¹ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Cosmos DBã«ä¿å­˜ã™ã‚‹
        
        Args:
            summary_title: è¦ç´„ã®ã‚¿ã‚¤ãƒˆãƒ«
            summary_content: è¦ç´„ã®å†…å®¹
            expert_id: ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆID
            tag_ids: ã‚¿ã‚°IDï¼ˆå˜ä¸€ã®intã€ãƒªã‚¹ãƒˆã€ã¾ãŸã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ï¼‰
            summary_id: è¦ç´„IDï¼ˆæŒ‡å®šã•ã‚Œãªã„å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœã®è©³ç´°
        """
        try:
            # summary_idãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯è‡ªå‹•ç”Ÿæˆ
            if summary_id is None:
                summary_id = f"summary_{datetime.now(JST).strftime('%Y%m%d_%H%M%S')}"
            
            # tag_idsã‚’æ­£è¦åŒ–ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«å¤‰æ›ï¼‰
            tag_ids_str = self._normalize_tag_ids(tag_ids)
            
            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆï¼ˆå†…å®¹ã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹ï¼‰
            text_to_embed = f"{summary_title}\n{summary_content}"
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            print(f"ğŸ” è¦ç´„å†…å®¹ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
            embedding = self.embeddings.embed_query(text_to_embed)
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æº–å‚™
            document = {
                "_id": summary_id,
                "summary_id": summary_id,
                "title": summary_title,
                "summary": summary_content,
                    "expert_id": expert_id,
                "tag_ids": tag_ids_str,  # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—
                "type": "summary",
                "vector": embedding,
                "created_at": datetime.now(JST).isoformat(),
                "updated_at": datetime.now(JST).isoformat()
            }
            
            # Cosmos DBã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜
            print(f"ğŸ’¾ Cosmos DBã«è¦ç´„ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿å­˜ä¸­...")
            result = self.collection.insert_one(document)
            
            if result.inserted_id:
                return {
                    "success": True,
                    "message": f"è¦ç´„å†…å®¹ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Cosmos DBã«ä¿å­˜ã—ã¾ã—ãŸ",
                    "summary_id": summary_id,
                    "document_id": str(result.inserted_id),
                    "vector": embedding,
                }
            else:
                return {
                    "success": False,
                    "message": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"
                }

        except Exception as e:
            print(f"âŒ è¦ç´„ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "success": False,
                "message": f"ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }

    # ===== è¿½åŠ : é¡ä¼¼åº¦è¨ˆç®—ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨ç™»éŒ²å‡¦ç† =====

    @staticmethod
    def _cosine_similarity(vector_a: List[float], vector_b: List[float]) -> float:
        """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        if not vector_a or not vector_b:
            return 0.0
        # é•·ã•ãŒç•°ãªã‚‹å ´åˆã¯å®‰å…¨å´ã§çŸ­ã„æ–¹ã«åˆã‚ã›ã‚‹
        dim = min(len(vector_a), len(vector_b))
        a = vector_a[:dim]
        b = vector_b[:dim]
        dot = sum(x * y for x, y in zip(a, b))
        norm_a = sum(x * x for x in a) ** 0.5
        norm_b = sum(y * y for y in b) ** 0.5
        if norm_a == 0 or norm_b == 0:
            return 0.0
        return float(dot / (norm_a * norm_b))

    def register_expert_tag_similarities(
        self,
        db: Session,
        *,
        summary_vector: List[float],
        expert_id: str,
        tag_ids: List[int],
    ) -> Dict[str, Any]:
        """
        - æ¸¡ã•ã‚ŒãŸsummary_vectorã¨ã€MySQLã®policy_tags.embeddingï¼ˆJSONï¼‰ã«å…¥ã£ã¦ã„ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
        - çµæœã‚’experts_policy_tagsã«ç™»éŒ²
        """
        try:
            # åŒä¸€ expert Ã— æŒ‡å®šã‚¿ã‚°ç¾¤ ã®æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤
            experts_policy_tags_crud.delete_by_expert_and_tags(db, expert_id=expert_id, tag_ids=tag_ids)

            # ã‚¿ã‚°ã‚’å–å¾—
            policy_tags = policy_tag_crud.get_policy_tags_by_ids(db, tag_ids)
            records: List[ExpertsPolicyTag] = []

            for tag in policy_tags:
                if not tag.embedding:
                    # åŸ‹ã‚è¾¼ã¿æœªç”Ÿæˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    continue
                try:
                    payload = json.loads(tag.embedding)
                    tag_vector = payload.get("vector")
                    if not isinstance(tag_vector, list):
                        continue
                except Exception:
                    continue

                sim = self._cosine_similarity(summary_vector, tag_vector)
                # DECIMAL(3,2)ã«ä¸¸ã‚ã‚‹
                relation_score = round(sim, 2)
                record = ExpertsPolicyTag(expert_id=expert_id, policy_tag_id=tag.id, relation_score=relation_score)
                records.append(record)

            if records:
                experts_policy_tags_crud.bulk_create(db, records)

            return {
                "success": True,
                "inserted_count": len(records),
            }
        except Exception as e:
            print(f"âŒ é¡ä¼¼åº¦ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "success": False,
                "message": f"é¡ä¼¼åº¦ç™»éŒ²ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            }

    def _normalize_tag_ids(self, tag_ids: Union[int, List[int], str]) -> str:
        """
        tag_idsã‚’æ­£è¦åŒ–ã—ã¦ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹
        
        Args:
            tag_ids: ã‚¿ã‚°IDï¼ˆå˜ä¸€ã®intã€ãƒªã‚¹ãƒˆã€ã¾ãŸã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ï¼‰
            
        Returns:
            str: ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ã‚¿ã‚°IDæ–‡å­—åˆ—
        """
        if isinstance(tag_ids, int):
            return str(tag_ids)
        elif isinstance(tag_ids, list):
            return ",".join(map(str, tag_ids))
        elif isinstance(tag_ids, str):
            # æ—¢ã«ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
            return tag_ids
        else:
            raise ValueError(f"Unsupported tag_ids type: {type(tag_ids)}")

    def _parse_tag_ids(self, tag_ids_str: str) -> List[int]:
        """
        ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ã‚¿ã‚°IDæ–‡å­—åˆ—ã‚’æ•´æ•°ãƒªã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹
        
        Args:
            tag_ids_str: ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ã‚¿ã‚°IDæ–‡å­—åˆ—
            
        Returns:
            List[int]: ã‚¿ã‚°IDã®æ•´æ•°ãƒªã‚¹ãƒˆ
        """
        if not tag_ids_str:
            return []
        return [int(tag_id.strip()) for tag_id in tag_ids_str.split(",") if tag_id.strip()]

    def search_similar_summaries(
        self, 
        query: str, 
        top_k: int = 5,
        expert_id: int = None,
        tag_ids: Union[int, List[int], str] = None
    ) -> List[Dict[str, Any]]:
        """
        ã‚¯ã‚¨ãƒªã«é¡ä¼¼ã—ãŸè¦ç´„ã‚’æ¤œç´¢ã™ã‚‹
        
        Args:
            query (str): æ¤œç´¢ã‚¯ã‚¨ãƒª
            top_k (int): è¿”ã™çµæœã®æ•°
            expert_id (int, optional): ç‰¹å®šã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§çµã‚Šè¾¼ã¿
            tag_ids (Union[int, List[int], str], optional): ç‰¹å®šã®ã‚¿ã‚°ã§çµã‚Šè¾¼ã¿
            
        Returns:
            List[Dict[str, Any]]: é¡ä¼¼ã—ãŸè¦ç´„ã®ãƒªã‚¹ãƒˆ
        """
        try:
            # ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            query_embedding = self.embeddings.embed_query(query)
            
            # æ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰
            pipeline = [
                {
                    "$search": {
                        "vectorSearch": {
                            "queryVector": query_embedding,
                            "path": "vector",
                            "numCandidates": top_k * 10,  # ã‚ˆã‚Šå¤šãã®å€™è£œã‚’å–å¾—
                            "limit": top_k
                        }
                    }
                }
            ]
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‚’è¿½åŠ 
            if expert_id is not None:
                pipeline.append({"$match": {"expert_id": expert_id}})
            
            # æ¤œç´¢å®Ÿè¡Œ
            results = list(self.collection.aggregate(pipeline))
            
            # çµæœã‚’æ•´å½¢
            similar_summaries = []
            for result in results:
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¿ã‚°IDã‚’å–å¾—
                tag_ids_str = result.get("tag_ids", "")
                tag_ids_list = self._parse_tag_ids(tag_ids_str)
                
                # ã‚¿ã‚°IDãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯çµã‚Šè¾¼ã¿
                if tag_ids is not None:
                    search_tag_ids = self._parse_tag_ids(self._normalize_tag_ids(tag_ids))
                    # å…±é€šã®ã‚¿ã‚°IDãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    if not any(tag_id in tag_ids_list for tag_id in search_tag_ids):
                        continue
                
                similar_summaries.append({
                    "summary_id": result.get("summary_id"),
                    "title": result.get("title"),
                    "summary": result.get("summary"),
                    "expert_id": result.get("expert_id"),
                    "tag_ids": tag_ids_list,  # æ•´æ•°ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã™
                    "tag_ids_str": tag_ids_str,  # å…ƒã®æ–‡å­—åˆ—ã‚‚ä¿æŒ
                    "score": result.get("score", 0.0),
                    "created_at": result.get("created_at")
                })
            
            return similar_summaries

        except Exception as e:
            print(f"âŒ è¦ç´„æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []

    def delete_summary_vector(self, summary_id: str) -> Dict[str, Any]:
        """
        æŒ‡å®šã•ã‚ŒãŸè¦ç´„IDã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’å‰Šé™¤ã™ã‚‹
        
        Args:
            summary_id: å‰Šé™¤ã™ã‚‹è¦ç´„ã®ID
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœã®è©³ç´°
        """
        try:
            # Cosmos DBã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤
            result = self.collection.delete_one({"_id": summary_id})
            
            if result.deleted_count > 0:
                return {
                    "success": True,
                    "message": f"è¦ç´„ãƒ™ã‚¯ãƒˆãƒ« (ID: {summary_id}) ã‚’å‰Šé™¤ã—ã¾ã—ãŸ",
                    "summary_id": summary_id
                }
            else:
                return {
                    "success": False,
                    "message": f"è¦ç´„ãƒ™ã‚¯ãƒˆãƒ« (ID: {summary_id}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
                }

        except Exception as e:
            print(f"âŒ è¦ç´„ãƒ™ã‚¯ãƒˆãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "success": False,
                "message": f"ãƒ™ã‚¯ãƒˆãƒ«å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }

    def get_vector_statistics(self) -> Dict[str, Any]:
        """
        Cosmos DBã®ãƒ™ã‚¯ãƒˆãƒ«çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹
        
        Returns:
            Dict[str, Any]: çµ±è¨ˆæƒ…å ±
        """
        try:
            # ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°ã‚’å–å¾—
            total_count = self.collection.count_documents({})
            
            # è¦ç´„ã‚¿ã‚¤ãƒ—ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°ã‚’å–å¾—
            summary_count = self.collection.count_documents({"type": "summary"})
            
            # ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆåˆ¥ã®çµ±è¨ˆã‚’å–å¾—
            expert_stats = list(self.collection.aggregate([
                {"$match": {"type": "summary"}},
                {"$group": {"_id": "$expert_id", "count": {"$sum": 1}}},
                {"$sort": {"count": -1}}
            ]))
            
            return {
                "success": True,
                "total_document_count": total_count,
                "summary_document_count": summary_count,
                "vector_dimension": self.vector_dimension,
                "expert_statistics": expert_stats,
                "database_name": self.database_name,
                "collection_name": self.collection_name
            }

        except Exception as e:
            print(f"âŒ çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "success": False,
                "message": f"çµ±è¨ˆæƒ…å ±å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }

    def close_connection(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’é–‰ã˜ã‚‹"""
        if self.client:
            self.client.close()

    # ========== æ”¿ç­–ã‚¿ã‚°é–¢é€£ã®ãƒ¡ã‚½ãƒƒãƒ‰ ==========

    def vectorize_policy_tags(self, db: Session) -> Dict[str, Any]:
        """
        MySQLã®policy_tagsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€
        ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Cosmos DBã«ä¿å­˜ã™ã‚‹
        
        Args:
            db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœã®è©³ç´°
        """
        try:
            # MySQLã‹ã‚‰å…¨ã¦ã®policy_tagsã‚’å–å¾—
            policy_tags = policy_tag_crud.get_all_policy_tags(db)
            
            if not policy_tags:
                return {
                    "success": False,
                    "message": "æ”¿ç­–ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                    "processed_count": 0
                }

            print(f"ğŸ“‹ {len(policy_tags)}å€‹ã®æ”¿ç­–ã‚¿ã‚°ã‚’å‡¦ç†ä¸­...")

            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            texts_to_embed = []
            documents_to_insert = []

            for tag in policy_tags:
                # name + description + keywords ã‚’çµåˆã—ã¦è¡¨ç¾åŠ›ã‚’å¼·åŒ–
                parts = [tag.name or ""]
                if getattr(tag, "description", None):
                    parts.append(str(tag.description))
                if getattr(tag, "keywords", None):
                    parts.append(str(tag.keywords))
                text = "\n".join([p for p in parts if p])
                texts_to_embed.append(text)
                
                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ™ãƒ¼ã‚¹ã‚’æº–å‚™ï¼ˆvectorã¯å¾Œã§è¿½åŠ ï¼‰
                document = {
                    "_id": f"policy_tag_{tag.id}",
                    "policy_tag_id": tag.id,
                    "name": tag.name,
                    "type": "policy_tag",
                    "text": text,
                    "created_at": tag.created_at.isoformat() if tag.created_at else datetime.now(JST).isoformat(),
                    "updated_at": datetime.now(JST).isoformat()
                }
                documents_to_insert.append(document)

            # ä¸€æ‹¬ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            print(f"ğŸ” {len(texts_to_embed)}å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
            embeddings_list = self.embeddings.embed_documents(texts_to_embed)
            
            # ãƒ™ã‚¯ãƒˆãƒ«ã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¿½åŠ 
            for i, embedding in enumerate(embeddings_list):
                documents_to_insert[i]["vector"] = embedding
                
                # MySQLã®embeddingã‚«ãƒ©ãƒ ã«ã‚‚ä¿å­˜
                tag = policy_tags[i]
                embedding_data = {
                    "vector": embedding,
                    "text": texts_to_embed[i],
                    "metadata": {
                        "tag_id": tag.id,
                        "tag_name": tag.name,
                        "type": "policy_tag",
                        "created_at": tag.created_at.isoformat() if tag.created_at else None
                    }
                }
                tag.embedding = json.dumps(embedding_data, ensure_ascii=False)
            
            # MySQLã®å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
            db.commit()

            # Cosmos DBã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¸€æ‹¬æŒ¿å…¥
            print(f"ğŸ’¾ Cosmos DBã«{len(documents_to_insert)}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜ä¸­...")
            
            # æ—¢å­˜ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
            self.collection.delete_many({"type": "policy_tag"})
            
            # æ–°ã—ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æŒ¿å…¥
            result = self.collection.insert_many(documents_to_insert)

            return {
                "success": True,
                "message": f"{len(result.inserted_ids)}å€‹ã®æ”¿ç­–ã‚¿ã‚°ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Cosmos DBã«ä¿å­˜ã—ã¾ã—ãŸ",
                "processed_count": len(result.inserted_ids),
                "inserted_ids": [str(id) for id in result.inserted_ids]
            }

        except Exception as e:
            print(f"âŒ æ”¿ç­–ã‚¿ã‚°ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "success": False,
                "message": f"ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                "processed_count": 0
            }

    def vectorize_single_policy_tag(self, db: Session, tag_id: int) -> Dict[str, Any]:
        """
        æŒ‡å®šã•ã‚ŒãŸIDã®æ”¿ç­–ã‚¿ã‚°ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Cosmos DBã«ä¿å­˜ã™ã‚‹
        
        Args:
            db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
            tag_id: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹ã‚¿ã‚°ã®ID
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœã®è©³ç´°
        """
        try:
            # æŒ‡å®šã•ã‚ŒãŸIDã®æ”¿ç­–ã‚¿ã‚°ã‚’å–å¾—
            policy_tag = policy_tag_crud.get_policy_tag_by_id(db, tag_id)
            
            if not policy_tag:
                return {
                    "success": False,
                    "message": f"ID {tag_id} ã®æ”¿ç­–ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                    "processed_count": 0
                }

            # idã¨nameã‚’çµ„ã¿åˆã‚ã›ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
            text = f"ID: {policy_tag.id}, Name: {policy_tag.name}"
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆname + description + keywordsï¼‰
            print(f"ğŸ” æ”¿ç­–ã‚¿ã‚° (ID: {tag_id}) ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
            parts = [policy_tag.name or ""]
            if getattr(policy_tag, "description", None):
                parts.append(str(policy_tag.description))
            if getattr(policy_tag, "keywords", None):
                parts.append(str(policy_tag.keywords))
            text = "\n".join([p for p in parts if p])
            embedding = self.embeddings.embed_query(text)
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æº–å‚™
            document = {
                "_id": f"policy_tag_{policy_tag.id}",
                "policy_tag_id": policy_tag.id,
                "name": policy_tag.name,
                "type": "policy_tag",
                "text": text,
                "vector": embedding,
                "created_at": policy_tag.created_at.isoformat() if policy_tag.created_at else datetime.now(JST).isoformat(),
                "updated_at": datetime.now(JST).isoformat()
            }
            
            # MySQLã®embeddingã‚«ãƒ©ãƒ ã«ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            embedding_data = {
                "vector": embedding,
                "text": text,
                "metadata": {
                    "tag_id": policy_tag.id,
                    "tag_name": policy_tag.name,
                    "type": "policy_tag",
                    "created_at": policy_tag.created_at.isoformat() if policy_tag.created_at else None
                }
            }
            policy_tag.embedding = json.dumps(embedding_data, ensure_ascii=False)
            db.commit()
            
            # Cosmos DBã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜
            print(f"ğŸ’¾ Cosmos DBã«æ”¿ç­–ã‚¿ã‚° (ID: {tag_id}) ã‚’ä¿å­˜ä¸­...")
            result = self.collection.replace_one(
                {"_id": f"policy_tag_{policy_tag.id}"},
                document,
                upsert=True
            )
            
            return {
                "success": True,
                "message": f"æ”¿ç­–ã‚¿ã‚° (ID: {tag_id}) ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Cosmos DBã«ä¿å­˜ã—ã¾ã—ãŸ",
                "processed_count": 1,
                "tag_id": tag_id,
                "tag_name": policy_tag.name
            }

        except Exception as e:
            print(f"âŒ æ”¿ç­–ã‚¿ã‚°ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "success": False,
                "message": f"ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                "processed_count": 0
            }

    def search_similar_policy_tags(
        self, 
        query: str, 
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ã‚¯ã‚¨ãƒªã«é¡ä¼¼ã—ãŸæ”¿ç­–ã‚¿ã‚°ã‚’æ¤œç´¢ã™ã‚‹
        
        Args:
            query (str): æ¤œç´¢ã‚¯ã‚¨ãƒª
            top_k (int): è¿”ã™çµæœã®æ•°
            
        Returns:
            List[Dict[str, Any]]: é¡ä¼¼ã—ãŸæ”¿ç­–ã‚¿ã‚°ã®ãƒªã‚¹ãƒˆ
        """
        try:
            # ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            query_embedding = self.embeddings.embed_query(query)
            
            # æ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰
            pipeline = [
                {
                    "$search": {
                        "vectorSearch": {
                            "queryVector": query_embedding,
                            "path": "vector",
                            "numCandidates": top_k * 10,  # ã‚ˆã‚Šå¤šãã®å€™è£œã‚’å–å¾—
                            "limit": top_k
                        }
                    }
                },
                {"$match": {"type": "policy_tag"}}
            ]
            
            # æ¤œç´¢å®Ÿè¡Œ
            results = list(self.collection.aggregate(pipeline))
            
            # çµæœã‚’æ•´å½¢
            similar_tags = []
            for result in results:
                similar_tags.append({
                    "policy_tag_id": result.get("policy_tag_id"),
                    "name": result.get("name"),
                    "text": result.get("text"),
                    "score": result.get("score", 0.0),
                    "created_at": result.get("created_at")
                })
            
            return similar_tags

        except Exception as e:
            print(f"âŒ æ”¿ç­–ã‚¿ã‚°æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []

    def delete_policy_tag_vector(self, tag_id: int) -> Dict[str, Any]:
        """
        æŒ‡å®šã•ã‚ŒãŸæ”¿ç­–ã‚¿ã‚°IDã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’å‰Šé™¤ã™ã‚‹
        
        Args:
            tag_id: å‰Šé™¤ã™ã‚‹æ”¿ç­–ã‚¿ã‚°ã®ID
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœã®è©³ç´°
        """
        try:
            # Cosmos DBã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤
            result = self.collection.delete_one({"_id": f"policy_tag_{tag_id}"})
            
            if result.deleted_count > 0:
                return {
                    "success": True,
                    "message": f"æ”¿ç­–ã‚¿ã‚°ãƒ™ã‚¯ãƒˆãƒ« (ID: {tag_id}) ã‚’å‰Šé™¤ã—ã¾ã—ãŸ",
                    "tag_id": tag_id
                }
            else:
                return {
                    "success": False,
                    "message": f"æ”¿ç­–ã‚¿ã‚°ãƒ™ã‚¯ãƒˆãƒ« (ID: {tag_id}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
                }

        except Exception as e:
            print(f"âŒ æ”¿ç­–ã‚¿ã‚°ãƒ™ã‚¯ãƒˆãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "success": False,
                "message": f"ãƒ™ã‚¯ãƒˆãƒ«å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }

# ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
cosmos_vector_service = CosmosVectorService()
